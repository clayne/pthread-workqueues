We have three "job queues," each corresponding to one of the priorities (High, Medium, and Low). "Job queues" are not the workqueues themselves. Each "job queue" is guarded by a lock. (Eventually, these queues may become "buckets" for the individual workqueues, depending on how fair we deem the priorities to be.)  The number of items in all three job queues at any given time is tracked by a single counting semaphore. When a workitem is added to a queue, it is packaged up in a job structure and placed into the job queue of appropriate priority for the workqueue. The semaphore is then signaled/uped. 

A pool of threads waits on the job queue semaphore. They may wake up at times even with nothing to do to ensure that they shouldn't be reaped, or to do house cleaning, but that's for another time. When a thread is woken up, it scans the job queues in order of priority and dequeues the first job it finds. It runs that job.

Things still unknown:
What goes in the structures
	Another idea: threads are directly added to the threadpool by a daemon thread, but removal is done by setting a counter. Threads check this counter either periodically when waiting for work or when exiting from a job or both. If the counter is non-zero, the thread decrements it and dies. Care must be taken to not kill everybody. 
What checks should the threads perform before and after running jobs. 
Fairness?

Problems:
This doesn't allow us to figure out what to do with the "overcommit" flag. It is impossible to have per-queue granularity under the current model.

